{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Check In 2\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping\n",
    "I have scraped the data in a seperate script. I have included it here commented out so it is visible how I did it but there's no need to rerun it of course. I have elected to use Steam data from user reviews. I am interested in comparing trends between reviews of games that have female protagonists versus games with male protagonists. Finding games with female protagonists was the hardest part, so I selected {list}. Then I selected games with male protagonists that I tried to map 1 to 1 with the female protagonist games (same year Â± 1, similar genre, etc.) as these are likely to be potentially confounding variables in comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import requests\n",
    "import urllib.parse\n",
    "from time import sleep\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from urllib.parse import quote\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "KEY = os.getenv('KEY')\n",
    "\n",
    "def getUserReviews(reviewAppid, params):\n",
    "    #userReviewsUrl = f'https://store.steampowered.com/appreviews/{reviewAppid}'\n",
    "    cursor = params['cursor']\n",
    "    userReviewsUrl = f\"https://store.steampowered.com/appreviews/{reviewAppid}?json=1&cursor={cursor}&filter_offtopic_activity=0&filter=recent&language=english&num_per_page=100\"\n",
    "    userReviewsResponse = requests.get(\n",
    "            userReviewsUrl,\n",
    "            #params=params\n",
    "        )\n",
    "    print(f\"Status Code: {userReviewsResponse.status_code}\")\n",
    "    \n",
    "\n",
    "    if (userReviewsResponse.status_code != 200) and (userReviewsResponse.status_code != 429):\n",
    "        print(f'Fail to get response for {reviewAppid}. Status code: {userReviewsResponse.status_code}')\n",
    "        return {'success' : 0}, userReviewsResponse.status_code\n",
    "    try:\n",
    "        userReviews = userReviewsResponse.json()\n",
    "    except:\n",
    "        return {\"success\": 0}, userReviewsResponse.status_code\n",
    "    return userReviews, userReviewsResponse.status_code\n",
    "\n",
    "gamesOfInterestFemale = {\n",
    "    '870780' : 'Control Ultimate Edition',\n",
    "    '752590' : 'A Plague Tale Innocence',\n",
    "    '750920' : 'Shadow of the Tomb Raider',\n",
    "    '414340' : \"Hellblade: Senua's Sacrifice\",\n",
    "    '524220' : 'Nier:Automata',\n",
    "    '1265920' : 'Life is Strange Remastered',\n",
    "}\n",
    "\n",
    "gamesOfInterestMale = {\n",
    "    '108710' : 'Alan Wake',\n",
    "    '532210' : 'Life is Strange 2',\n",
    "    '1659420' : 'Uncharted: Legacy of Thieves Collection',\n",
    "    '814380' : 'Sekiro: Shadows Die Twice - GOTY Edition',\n",
    "    '1687950' : 'Persona 5 Royal',\n",
    "    '2050650' : 'Resident Evil 4'\n",
    "}\n",
    "\n",
    "allGamesOfInterest = {\n",
    "    'female' : gamesOfInterestFemale,\n",
    "    'male' : gamesOfInterestMale    \n",
    "}\n",
    "\n",
    "def parseResponse(gameId, gameTitle):\n",
    "    reviewsSkipped = 0\n",
    "    reviews = []\n",
    "    name = gameTitle\n",
    "    reviewMax = 100\n",
    "    #reviewMax = 20\n",
    "    params = {\n",
    "            #'json' : 1,\n",
    "            #'language' : 'english',\n",
    "            'cursor' : '*',\n",
    "            #'filter_offtopic_activity' : 1,\n",
    "            #'num_per_page': 100,\n",
    "            #'key' : KEY,\n",
    "            #'filter' : 'recent'\n",
    "    }\n",
    "    while(True):\n",
    "        reviewMin = reviewMax - 100\n",
    "        #reviewMin = reviewMax - 20\n",
    "        print(f\"Getting Reviews: {reviewMin}-{reviewMax} for {name}\")\n",
    "        print(f\"Params: {params}\")\n",
    "        response,status = getUserReviews(gameId,params)\n",
    "        if status == 429:\n",
    "            print(f\"Rate Limiting\")\n",
    "            sleep(300)\n",
    "            continue\n",
    "        print(f\"Extracted {len(response['reviews'])} reviews\")\n",
    "        #print(response['reviews'])\n",
    "        #if response['success'] != 1:\n",
    "        #    print(f'Fail to get response for {gameId}.')\n",
    "        #    return {'allReviewsGot' : 0}, []\n",
    "\n",
    "        for review in response['reviews']:\n",
    "            try:\n",
    "                recommendationId = review['recommendationid']\n",
    "\n",
    "                timestampCreated = review['timestamp_created']\n",
    "                timestampUpdated = review['timestamp_updated']\n",
    "\n",
    "                authorSteamId = review['author']['steamid']\n",
    "                playtimeForever = review['author']['playtime_forever']\n",
    "                playtimeLastTwoWeeks = review['author']['playtime_last_two_weeks']\n",
    "                playtimeAtReviewMinutes = review['author']['playtime_at_review']\n",
    "                lastPlayed = review['author']['last_played']\n",
    "\n",
    "                reviewText = review['review']\n",
    "                votedUp = review['voted_up']\n",
    "                votesUp = review['votes_up']\n",
    "                votesFunny = review['votes_funny']\n",
    "                weightedVoteScore = review['weighted_vote_score']\n",
    "                steamPurchase = review['steam_purchase']\n",
    "                receivedForFree = review['received_for_free']\n",
    "                writtenDuringEarlyAccess = review['written_during_early_access']\n",
    "\n",
    "                myReviewDict = {\n",
    "                    'recommendationid': recommendationId,\n",
    "                    'authorSteamid': authorSteamId,\n",
    "                    'playtimeAtReviewMinutes': playtimeAtReviewMinutes,\n",
    "                    'playtimeForeverMinutes': playtimeForever,\n",
    "                    'playtimeLastTwoWeeksMinutes': playtimeLastTwoWeeks,\n",
    "                    'lastPlayed': lastPlayed,\n",
    "\n",
    "                    'reviewText': reviewText,\n",
    "                    'timestampCreated': timestampCreated,\n",
    "                    'timestampUpdated': timestampUpdated,\n",
    "\n",
    "                    'votedUp': votedUp,\n",
    "                    'votesUp': votesUp,\n",
    "                    'votesFunny': votesFunny,\n",
    "                    'weightedVoteScore': weightedVoteScore,\n",
    "                    'steamPurchase': steamPurchase,\n",
    "                    'receivedForFree': receivedForFree,\n",
    "                    'writtenDuringEarlyAccess': writtenDuringEarlyAccess,\n",
    "                }\n",
    "                reviews.append(myReviewDict)\n",
    "            except:\n",
    "                print(\"Skipped Review\")\n",
    "                reviewsSkipped += 1\n",
    "                print(f'Reviews Skipped: {reviewsSkipped}')\n",
    "        if response['cursor'] == params['cursor']:\n",
    "            return reviews\n",
    "        \n",
    "        if response['query_summary']['num_reviews'] == 0:\n",
    "            print(f'No more reviews: {response}')\n",
    "            return reviews\n",
    "        \n",
    "        try:\n",
    "            cursor = response['cursor']\n",
    "            print(cursor)\n",
    "            params['cursor'] = quote(cursor)\n",
    "            print(params['cursor'])\n",
    "        except:\n",
    "            return reviews\n",
    "        \n",
    "        reviewMax += 100\n",
    "        #reviewMax += 20\n",
    "        sleep(1.5)\n",
    "\n",
    "\n",
    "\n",
    "steamIDs = ['870780','752590','750920','414340','524220','1265920','108710','532210','1659420','814380','1687950','2050650']\n",
    "\n",
    "for key,items in allGamesOfInterest.items():\n",
    "        for key,val in items.items():\n",
    "            reviews = parseResponse(key,val)\n",
    "            title = val.strip().replace(\" \",\"_\").lower()\n",
    "            titleClean = re.sub(r'[^\\w_. -]', '_', title)\n",
    "            data = {key : reviews}\n",
    "            with open(f'./data/pkl/{titleClean}.pkl','wb') as f:\n",
    "                pickle.dump(data,f)\n",
    "            try:\n",
    "                steamIDs.remove(key)\n",
    "                print(f\"{len(steamIDs)} games left\")\n",
    "            except:\n",
    "                print(\"Crying is a free action\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning\n",
    "Due to the nature of steam being a place of informal reviews, a lot of text cleaning has to be done to the reviews which ultimately does reduce the amount of data but the data available is relatively clean. I have commented out my process but it is essentially: \n",
    "load -> remove excess scraped data -> remove reviews missing elements to filter by -> filter by playtime >3hrs and within two week palytime of review writing >15 mins -> remove emoji and extra whitespace -> remove links -> clear out non enlish reviews (apparently steam language tags aren't very good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "from collections import Counter\n",
    "from lingua import Language, LanguageDetectorBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(file):\n",
    "    with open(file,'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def extractData(review):\n",
    "    recId = review['recommendationid']\n",
    "    reviewPlaytime = review['playtimeAtReviewMinutes']\n",
    "    earlyAccessReview = review['writtenDuringEarlyAccess']\n",
    "    votedUp = review['votedUp']\n",
    "    helpfulness = review['weightedVoteScore']\n",
    "    recentPlaytime = review['playtimeLastTwoWeeksMinutes']\n",
    "    \n",
    "    text = review['reviewText']\n",
    "    \n",
    "    trimmedData = {\n",
    "        'id' : recId,\n",
    "        'playtime' : reviewPlaytime,\n",
    "        'recentPlaytime' : recentPlaytime,\n",
    "        'earlyAccess' : earlyAccessReview,\n",
    "        'votedUp' : votedUp,\n",
    "        'helpfulness' : helpfulness\n",
    "    }\n",
    "    \n",
    "    return trimmedData, text\n",
    "\n",
    "def isEnglish(string):\n",
    "  return string.isascii()\n",
    "\n",
    "def cleanData(reviews):\n",
    "    languages = [Language.ENGLISH, Language.SPANISH, Language.PORTUGUESE]\n",
    "    detector = LanguageDetectorBuilder.from_languages(*languages).build()\n",
    "    for review in reviews:\n",
    "        data, text = extractData(review)\n",
    "        if (data['playtime'] == None) or (data['recentPlaytime'] == None):\n",
    "            continue\n",
    "        elif (int(data['playtime']) >= 180) and (int(data['recentPlaytime']) >= 15):\n",
    "            #Removes emoji like characters\n",
    "            normText = re.sub(r\"[^\\w\\s\\.,!?;:\\(\\)\\[\\]\\-\\+=\\{\\}\\|\\/\\<\\>.]\", '', text)\n",
    "            #Remove links\n",
    "            cleanText = re.sub(r\"\\[.*?\\]|(http|ftp|https):\\/\\/([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:\\/~+#-]*[\\w@?^=%&\\/~+#-])\", '', normText)\n",
    "            #Remove excess whitespace\n",
    "            cleanText = ' '.join(cleanText.split())\n",
    "            #Remove reviews that follow a specific pattern that results in odd text\n",
    "            if bool(re.search('---.*?---', cleanText)):\n",
    "                continue\n",
    "            #Check if string is ascii encoded\n",
    "            elif isEnglish(cleanText):\n",
    "                #Ignore reviews with less than 5 words\n",
    "                if sum(Counter(cleanText.split()).values()) < 5:\n",
    "                    continue\n",
    "                #Make sure review is in english\n",
    "                elif detector.detect_language_of(cleanText) != Language.ENGLISH:\n",
    "                    continue\n",
    "                else:\n",
    "                    return data, cleanText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Now we can finally do some nlp preprocessing using spaCy and generate plots and data using Wordcloud and Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "control = load(\"data/pkl/control_ultimate_edition.pkl\")['870780']\n",
    "plagueTale = load(\"data/pkl/a_plague_tale_innocence.pkl\")['752590'] \n",
    "tombRaider = load(\"data/pkl/shadow_of_the_tomb_raider.pkl\")['750920'] \n",
    "senuaSacrifice = load(\"data/pkl/hellblade__senua_s_sacrifice.pkl\")['414340']\n",
    "nierAutomata = load(\"data/pkl/nier_automata.pkl\")['524220'] \n",
    "lifeIsStrangeRem = load(\"data/pkl/life_is_strange_remastered.pkl\")['1265920'] \n",
    "\n",
    "re4 = load(\"data/pkl/resident_evil_4.pkl\")['2050650']\n",
    "alanWake = load(\"data/pkl/alan_wake.pkl\")['108710']\n",
    "lifeIsStrange2 = load(\"data/pkl/life_is_strange_2.pkl\")['532210'] \n",
    "uncharted = load(\"data/pkl/uncharted__legacy_of_thieves_collection.pkl\")['1659420']\n",
    "sekiro = load(\"data/pkl/sekiro__shadows_die_twice_-_goty_edition.pkl\")['814380'] \n",
    "persona5 = load(\"data/pkl/persona_5_royal.pkl\")['1687950']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textasdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
